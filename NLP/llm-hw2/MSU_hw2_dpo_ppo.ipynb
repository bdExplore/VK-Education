{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a86fe262-b2b3-48cf-b8ed-c4409648a78f",
      "metadata": {
        "id": "a86fe262-b2b3-48cf-b8ed-c4409648a78f"
      },
      "source": [
        "# –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ 2: DPO –∏ PPO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e70aa25-a6f3-4d56-b648-3da1b89c0c51",
      "metadata": {
        "id": "2e70aa25-a6f3-4d56-b648-3da1b89c0c51"
      },
      "source": [
        "–í —ç—Ç–æ–π –¥–æ–º–∞—à–∫–µ –ø–æ–±–ª–∏–∂–µ –ø–æ–∑–Ω–∞–∫–æ–º–∏–º—Å—è —Å –¥–≤—É–º—è –∫—Ä–∞–π–Ω–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –∞–ª–∞–π–º–µ–Ω—Ç–∞ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π. –í –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏ –≤–∞–º –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—Å—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –∑–∞–∏–º–ø–ª–µ–º–µ–Ω—Ç–∏—Ç—å DPO c –Ω—É–ª—è. –í–æ –≤—Ç–æ—Ä–æ–π —á–∞—Å—Ç–∏ –º—ã —É–∂–µ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É TRL –∏ –æ–±—É—á–∏–º PPO.\n",
        "\n",
        "–û–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –∏ –Ω—É–∂–Ω–æ –≤—ã–ª–æ–∂–∏—Ç—å –Ω–∞ [ü§ó HuggingFace](https://huggingface.co/). –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å —Ç–∞–º, –ø–æ–¥–ø–∏—à–∏—Ç–µ—Å—å –Ω–∞ [deep vk](https://huggingface.co/deepvk) –∏ —Å–æ–∑–¥–∞–π—Ç–µ —Å–µ–±–µ API —Ç–æ–∫–µ–Ω.\n",
        "\n",
        "–°–ª–µ–¥—É–π—Ç–µ —è—á–µ–π–∫–∞–º —Ç–µ—Ç—Ä–∞–¥–∫–∏ –∏ –∑–∞–ø–æ–ª–Ω—è–π—Ç–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —è—á–µ–π–∫–∏. –í –∫–æ–Ω—Ü–µ —Ç–µ—Ç—Ä–∞–¥–∫–∏ –≤—ã –Ω–∞–π–¥–µ—Ç–µ –∑–∞–¥–∞—á–∏ —Å–æ –∑–≤–µ–∑–¥–æ—á–∫–æ–π, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–ª!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a223a0b-6896-49f6-a5cf-0edc0984595b",
      "metadata": {
        "id": "6a223a0b-6896-49f6-a5cf-0edc0984595b"
      },
      "source": [
        "## –ò–º–ø–æ—Ä—Ç—ã –∏ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79504930-ceac-42a3-8d43-3f2fe4e7a5d4",
      "metadata": {
        "id": "79504930-ceac-42a3-8d43-3f2fe4e7a5d4"
      },
      "outputs": [],
      "source": [
        "# –£—Å—Ç–∞–Ω–æ–≤–∏–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
        "\n",
        "%pip install --quiet datasets trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1369a8cc-b9a4-4a52-a4df-a15489ea3352",
      "metadata": {
        "editable": true,
        "id": "1369a8cc-b9a4-4a52-a4df-a15489ea3352",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã (–¥–ª—è –æ–±–æ–∏—Ö —á–∞—Å—Ç–µ–π)\n",
        "import inspect\n",
        "import random\n",
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import HfApi, interpreter_login\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    PreTrainedTokenizerBase,\n",
        ")\n",
        "from trl import PPOConfig, PPOTrainer, RewardConfig, RewardTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0a8464f5",
      "metadata": {
        "id": "0a8464f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "interpreter_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7ce75b35",
      "metadata": {
        "id": "7ce75b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Homework repository: 'bdvs/llm-course-hw2'\n"
          ]
        }
      ],
      "source": [
        "# –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –¥–ª—è –±—É–¥—É—â–µ–π –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\n",
        "username = HfApi().whoami()[\"name\"]\n",
        "REPO_NAME = f\"{username}/llm-course-hw2\"  # –ò–ª–∏ –∫–∞–∫ –≤–∞–º —Ö–æ—á–µ—Ç—Å—è\n",
        "\n",
        "print(f\"Homework repository: '{REPO_NAME}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fa23203d-233f-4a30-aa5a-8ee669275caf",
      "metadata": {
        "editable": true,
        "id": "fa23203d-233f-4a30-aa5a-8ee669275caf",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "\n",
        "# –≠—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π –±—É–¥—É—Ç –ø–æ–º–µ—á–µ–Ω—ã –≤—Å–µ –º–µ—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ–∑–∞–ø–æ–ª–Ω–∏—Ç—å\n",
        "# –≠—Ç–æ –º–æ–≥—É—Ç –±—ã—Ç—å –∫–∞–∫ —Ü–µ–ª—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏, —Ç–∞–∫ –∏ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ –≤–Ω—É—Ç—Ä–∏ –Ω–∏—Ö\n",
        "# –í—Å–µ–≥–¥–∞ –º–æ–∂–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∏–Ω—Ç—Ä–æ—Å–ø–µ–∫—Ü–∏–µ–π –∏ –Ω–∞–π—Ç–∏ –º–µ—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ :)\n",
        "def todo():\n",
        "    stack = inspect.stack()\n",
        "    caller_frame = stack[1]\n",
        "    function_name = caller_frame.function\n",
        "    line_number = caller_frame.lineno\n",
        "    raise NotImplementedError(f\"TODO at {function_name}, line {line_number}\")\n",
        "\n",
        "\n",
        "def disable_dropout_in_model(model):\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, torch.nn.Dropout):\n",
        "            module.p = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8e36c1d-6e89-4643-a0bb-1a1c916c3466",
      "metadata": {
        "editable": true,
        "id": "e8e36c1d-6e89-4643-a0bb-1a1c916c3466",
        "tags": []
      },
      "source": [
        "# –ß–∞—Å—Ç—å 1: DPO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2ae081e-f2f6-4790-b239-a6ec1c0db1f2",
      "metadata": {
        "id": "b2ae081e-f2f6-4790-b239-a6ec1c0db1f2"
      },
      "source": [
        "–ö—Ä–∞–π–Ω–µ –ø—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –≤ —Å–≤–æ–µ –≤—Ä–µ–º—è –ø—Ä–æ–∏–∑–≤–µ–ª —Ñ—É—Ä–æ—Ä, —Ç.–∫. –≤—ã–≥–æ–¥–Ω–æ –≤—ã–¥–µ–ª—è–ª—Å—è –Ω–∞ —Ñ–æ–Ω–µ PPO. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç PPO, —Ç—Ä–µ–±—É—é—â–µ–≥–æ –æ—Ç–¥–µ–ª—å–Ω–æ –æ–±—É—á–∞—Ç—å Reward Model, Value Model –∏ –±–æ–ª—å—à–∏—Ö —É—Å–∏–ª–∏–π –≤ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏, DPO –Ω–µ —Ç—Ä–µ–±—É–µ—Ç —è–≤–Ω–æ–π —Ä–µ–≤–∞—Ä–¥ –º–æ–¥–µ–ª–∏, –∞ —Ç–æ–ª—å–∫–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–º–∏ –ø—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞–º–∏ –≤–∏–¥–∞: –ø—Ä–æ–º–ø—Ç, –≤—ã–±—Ä–∞–Ω–Ω—ã–π —á–µ–ª–æ–≤–µ–∫–æ–º –æ—Ç–≤–µ—Ç, –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç–Ω—ã–π —á–µ–ª–æ–≤–µ–∫–æ–º –æ—Ç–≤–µ—Ç. –ü—Ä–æ—Å—Ç–æ—Ç–∞ —Ç–∞–∫–∂–µ –≤–∏–¥–Ω–∞ –∏–∑ –ª–æ—Å—Å–∞, –ø–æ —Å—É—Ç–∏ —ç—Ç–æ –≤–µ—Å—å –º–µ—Ç–æ–¥:\n",
        "$$\n",
        "L_\\text{DPO}(\\pi_{\\theta}; \\pi_\\text{ref}) = -E_{(x, y_w, y_l)\\sim D}\\left[\\log \\sigma \\left(\n",
        "\\beta \\log \\frac{\\pi_{\\theta}(y_w\\mid x)}{\\pi_\\text{ref}(y_w\\mid x)} \\thinspace\n",
        "{- \\beta \\log \\frac{\\pi_{\\theta}(y_l\\mid x)}{\\pi_\\text{ref}(y_l\\mid x)}}\\right)\\right]\n",
        "$$\n",
        "\n",
        "–≥–¥–µ:\n",
        "\n",
        "- $\\pi_{\\theta}$ LLM –∫–æ—Ç–æ—Ä—É—é –º—ã —Ö–æ—Ç–∏–º –∑–∞–∞–ª–∞–π–Ω–∏—Ç—å\n",
        "- $\\pi_\\text{ref}$ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏, –∫–∞–∫ –ø—Ä–∞–≤–∏–ª–æ –ø—Ä–æ—Å—Ç–æ –Ω–∞—á–∞–ª—å–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç\n",
        "- $D$ –¥–∞—Ç–∞—Å–µ—Ç —Å –ø—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞–º–∏\n",
        "- $x$ –ø—Ä–æ–º–ø—Ç –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ $D$\n",
        "- $y_w$ –æ—Ç–≤–µ—Ç –Ω–∞ –ø—Ä–æ–º–ø—Ç $x$ –≤—ã–±—Ä–∞–Ω–Ω—ã–π —á–µ–ª–æ–≤–µ–∫–æ–º (–∏–ª–∏ —Ç–µ–º –∫—Ç–æ —Ä–∞–∑–º–µ—á–∞–ª –ø—Ä–µ—Ñ–µ—Ä–µ–Ω—Å—ã, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏ –±–æ–ª—å—à–∞—è LLM)\n",
        "- $y_l$ –æ—Ç–≤–µ—Ç –Ω–∞ –ø—Ä–æ–º–ø—Ç $x$ –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç—ã–π —á–µ–ª–æ–≤–µ–∫–æ–º (–∏–ª–∏ —Ç–µ–º –∫—Ç–æ —Ä–∞–∑–º–µ—á–∞–ª –ø—Ä–µ—Ñ–µ—Ä–µ–Ω—Å—ã, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏ –±–æ–ª—å—à–∞—è LLM)\n",
        "- $\\beta$ –≥–∏–ø–µ—Ä–µ–ø–∞—Ä–∞–º–µ—Ç—Ä –æ—Ç–≤–µ—á–∞—é—â–∏–π –∑–∞ —Ç–æ, –∫–∞–∫ –¥–∞–ª–µ–∫–æ –º—ã –º–æ–∂–µ–º –æ—Ç—Ö–æ–¥–∏—Ç—å –æ—Ç —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
        "\n",
        "–í–æ –≤—Ä–µ–º—è –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–æ–≤–µ—Ç—É–º –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç—å—é: [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/abs/2305.18290).\n",
        "\n",
        "–î–ª—è —Ñ–∞–π–Ω—Ç—é–Ω–∞ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å [HuggingFaceTB/SmolLM-135M-Instruct](https://huggingface.co/HuggingFaceTB/SmolLM-135M-Instruct), —Ç.–∫. –æ–Ω–∞ –º–∞–ª–µ–Ω—å–∫–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (–ø–æ–º–µ—Å—Ç–∏—Ç—Å—è –Ω–∞ Colab), –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º —É–º–µ–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç –∞–ª–∞–π–º–µ–Ω—Ç–∞. –ë–æ–ª–µ–µ —Ç–æ–≥–æ, –¥–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–∞–∂–µ –ø—Ä–æ—à–ª–∞ —Å—Ç–∞–¥–∏—é SFT, –∞ –ø–æ—ç—Ç–æ–º—É –≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ (–±–µ–∑ Instruct) –ø–æ–Ω–∏–º–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç —á–∞—Ç–∞ (chat-template –≤ transformers, –¥–∞–ª—å—à–µ —Ä–∞–∑–±–µ—Ä–µ–º) –∏ –∏–º–µ–µ—Ç '–æ—Å–æ–∑–Ω–∞–Ω–∏–µ' —Å–µ–±—è —è–∑—ã–∫–æ–≤—ã–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º.\n",
        "\n",
        "P.S. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–º —Ä–µ—Å—É—Ä—Å–∞–º —Ç–∏–ø–æ A100 –∏ –±–æ–ª—å—à–µ, –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∑–∞—Ñ–∞–π–Ω—Ç—é–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –±–æ–ª—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑ —ç—Ç–æ–π –∂–µ [–ª–∏–Ω–µ–π–∫–∏](https://huggingface.co/blog/smollm). –ë—É–¥—å—Ç–µ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã, —Å–º–æ—Ç—Ä–∏—Ç–µ, —á—Ç–æ–±—ã –æ–Ω–∞ –±—ã–ª–∞ —Å –¥–æ–±–∞–≤–∫–æ–π Instruct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3d88765f",
      "metadata": {
        "id": "3d88765f"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"HuggingFaceTB/SmolLM-135M-Instruct\"\n",
        "DATASET_ID = \"HumanLLMs/Human-Like-DPO-Dataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9004f808-b6bc-46fe-bc77-f7d4e381f963",
      "metadata": {
        "id": "9004f808-b6bc-46fe-bc77-f7d4e381f963"
      },
      "source": [
        "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö [2 –±–∞–ª–ª–∞]\n",
        "\n",
        "–î–ª—è –Ω–∞—á–∞–ª–∞ –Ω—É–∂–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ. –í –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–≤ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å [HumanLLMs/Human-Like-DPO-Dataset](https://huggingface.co/datasets/HumanLLMs/Human-Like-DPO-Dataset), –∫–æ—Ç–æ—Ä—ã–π –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø–æ–≤—ã—à–∞–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —ç–º–æ–¥–∑–∏ –∏ –≤ —Ü–µ–ª–æ–º —Å–Ω–∏–∂–∞–µ—Ç —Å—Ç—Ä–æ–≥–æ—Å—Ç—å —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —à–∞–±–ª–æ–Ω—É \"As a conversational AI, I ...\".\n",
        "\n",
        "–ß—Ç–æ–±—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –Ω—É–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç—ã—Ö —ç—Ç–∞–ø–æ–≤:\n",
        "1. –ü—Ä–∏–≤–µ—Å—Ç –¥–∞–Ω–Ω—ã–µ –∫ —Ñ–æ—Ä–º–∞—Ç—É chat-template\n",
        "2. –ü–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–∏—Ç—å —ç—Ç–æ—Ç chat-template —Å –ø–æ–º–æ—â—å—é 'tokenizer.apply_chat_template'\n",
        "3. –¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª—É—á–∏–≤—à–∏–µ—Å—è –¥–∞–Ω–Ω—ã–µ, –ø–æ–ø—É—Ç–Ω–æ –æ–±—Ä–µ–∑–∞–≤ –ø—Ä–æ–º–ø—Ç –∏ –æ—Ç–≤–µ—Ç—ã –¥–æ –Ω—É–∂–Ω–æ–π –¥–ª–∏–Ω—ã, –µ—Å–ª–∏ –Ω–∞–¥–æ.\n",
        "\n",
        "–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–π—Ç–µ [–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ chat-templates](https://huggingface.co/docs/transformers/chat_templating). –î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏–≤–æ–¥—è—Ç –≤ –Ω–∞—á–∞–ª–µ –≤ –±–æ–ª–µ–µ –≤–µ—Ä—Ö–Ω–µ-—É—Ä–æ–≤–Ω–µ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Ç–∞–∫–æ–≥–æ –≤–∏–¥–∞:\n",
        "```python\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant focused on technical topics.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Can you explain what a chat template is?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"A chat template structures conversations between users and AI models...\"}\n",
        "]\n",
        "```\n",
        "–¢–æ –µ—Å—Ç—å –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Ä–æ–ª–∏, —Ç–∞–∫–∏–µ –∫–∞–∫ –Ω–∞–ø—Ä–∏–º–µ—Ä —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –∏ –≤ —Ü–µ–ª–æ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∏–∞–ª–æ–≥ –º–µ–∂–¥—É –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º –∏ —á–µ–ª–æ–≤–µ–∫–æ–º. –û–±—ã—á–Ω–æ –æ–±—É—á–µ–Ω–∏–µ —ç—Ç–æ–º—É –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ —ç—Ç–∞–ø–µ SFT. –î–∞–Ω–Ω–∞—è —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è –∞–±—Å—Ç—Ä–∞–≥–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª–∏ (–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã) –∫–∞–∫ —ç—Ç–æ—Ç —Ñ–æ—Ä–º–∞—Ç –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏. –ß—Ç–æ–±—ã –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –µ–≥–æ –≤ –Ω–µ—Å–ø–æ—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∏–Ω–ø—É—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `tokenizer.apply_chat_template`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "553b75fe-e0b2-4c68-9c1e-9b2d58983da6",
      "metadata": {
        "id": "553b75fe-e0b2-4c68-9c1e-9b2d58983da6"
      },
      "outputs": [],
      "source": [
        "# –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "aa5e40e1-94a3-4ed9-8f33-1bd45fa9086d",
      "metadata": {
        "id": "aa5e40e1-94a3-4ed9-8f33-1bd45fa9086d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prompt': 'Oh, I just saw the best meme - have you seen it?',\n",
              " 'chosen': \"üòÇ Ah, no I haven't! I'm dying to know, what's the meme about? Is it a funny cat or a ridiculous situation? Spill the beans! ü§£\",\n",
              " 'rejected': \"I'm an artificial intelligence language model, I don't have personal experiences or opinions. However, I can provide you with information on highly-rated and critically acclaimed films, as well as recommendations based on specific genres or themes. Would you like me to suggest some notable movies or discuss a particular genre of interest?\"}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset(DATASET_ID, split=\"train\")\n",
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "565dcc5d-8e70-4917-97b8-ed8c7f08d964",
      "metadata": {
        "id": "565dcc5d-8e70-4917-97b8-ed8c7f08d964"
      },
      "source": [
        "–ü—Ä–∏–≤–µ–¥–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –∫ —Ñ–æ—Ä–º–∞—Ç—É —á–∞—Ç–∞, –≥–¥–µ —É –ø—Ä–æ–º–ø—Ç–∞ —Ä–æ–ª—å user, –∞ —É –æ—Ç–≤–µ—Ç–æ–≤ assistant, –∞ –ø–æ—Ç–æ–º –ø—Ä–∏–º–µ–Ω–∏—Ç–µ —á–∞—Ç —Ç–µ–º–ø–ª–µ–π—Ç:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6e06515d-abdc-4b3f-b4eb-b7b00c922bff",
      "metadata": {
        "id": "6e06515d-abdc-4b3f-b4eb-b7b00c922bff"
      },
      "outputs": [],
      "source": [
        "def apply_chat_template(example: dict[str, str], tokenizer: PreTrainedTokenizerBase) -> dict[str, str]:\n",
        "    \"\"\"\n",
        "    Transforms a dataset example into a formatted chat template using the provided tokenizer.\n",
        "\n",
        "    Args:\n",
        "        example (Dict[str, str]): A dictionary containing the following keys:\n",
        "            - \"prompt\": The initial user prompt.\n",
        "            - \"chosen\": The assistant's chosen response.\n",
        "            - \"rejected\": The assistant's rejected response.\n",
        "        tokenizer (PreTrainedTokenizerBase): An object that provides the `apply_chat_template` method\n",
        "            for formatting the conversation.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, str]: A dictionary with the following keys:\n",
        "            - \"prompt\": The formatted prompt string including the generation prompt.\n",
        "            - \"chosen\": The formatted assistant's chosen response (with the prompt prefix removed).\n",
        "            - \"rejected\": The formatted assistant's rejected response (with the prompt prefix removed).\n",
        "    \"\"\"\n",
        "    chosen_messages = [\n",
        "        {\"role\": \"user\", \"content\": example[\"prompt\"]},\n",
        "        {\"role\": \"assistant\", \"content\": example[\"chosen\"]}\n",
        "    ]\n",
        "    chosen_full = tokenizer.apply_chat_template(chosen_messages, tokenize=False)\n",
        "\n",
        "    rejected_messages = [\n",
        "        {\"role\": \"user\", \"content\": example[\"prompt\"]},\n",
        "        {\"role\": \"assistant\", \"content\": example[\"rejected\"]}\n",
        "    ]\n",
        "    rejected_full = tokenizer.apply_chat_template(rejected_messages, tokenize=False)\n",
        "\n",
        "    prompt_with_assistant = tokenizer.apply_chat_template(\n",
        "        [{\"role\": \"user\", \"content\": example[\"prompt\"]}], tokenize=False\n",
        "    ) + \"<|im_start|>assistant\\n\"\n",
        "\n",
        "    chosen_response = chosen_full[len(prompt_with_assistant):]\n",
        "    rejected_response = rejected_full[len(prompt_with_assistant):]\n",
        "\n",
        "    return {\n",
        "        \"prompt\": prompt_with_assistant,\n",
        "        \"chosen\": chosen_response,\n",
        "        \"rejected\": rejected_response\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fcb16881-c63a-41ae-b5ed-9a37b62a98ff",
      "metadata": {
        "id": "fcb16881-c63a-41ae-b5ed-9a37b62a98ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prompt': '<|im_start|>user\\nOh, I just saw the best meme - have you seen it?<|im_end|>\\n<|im_start|>assistant\\n',\n",
              " 'chosen': \"üòÇ Ah, no I haven't! I'm dying to know, what's the meme about? Is it a funny cat or a ridiculous situation? Spill the beans! ü§£<|im_end|>\\n\",\n",
              " 'rejected': \"I'm an artificial intelligence language model, I don't have personal experiences or opinions. However, I can provide you with information on highly-rated and critically acclaimed films, as well as recommendations based on specific genres or themes. Would you like me to suggest some notable movies or discuss a particular genre of interest?<|im_end|>\\n\"}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = dataset.map(apply_chat_template, fn_kwargs={\"tokenizer\": tokenizer})\n",
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b64dabac-883f-41db-b6d8-9fff5ae32d35",
      "metadata": {
        "id": "b64dabac-883f-41db-b6d8-9fff5ae32d35"
      },
      "source": [
        "–ü–æ—Å–ª–µ —ç—Ç–∏—Ö –¥–≤—É—Ö —ç—Ç–∞–ø–æ–≤ –¥–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –≤—ã–≥–ª—è–¥–µ—Ç—å —Ç–∞–∫ (**–æ–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –ø–æ–ª–æ–∂–µ–Ω–∏–µ <|im_start|>assistant\\n**, —ç—Ç–æ –≤–∞–∂–Ω–æ!):\n",
        "```\n",
        "{\n",
        "    'prompt': \"<|im_start|>user\\nOh, I just saw the best meme - have you seen it <|im_end|>\\n<|im_start|>assistant\\n\",\n",
        "    'chosen': \"üòÇ Ah, no I haven't! I'm dying to know, what's the meme about? Is it a funny cat or a ridiculous situation? Spill the beans! ü§£<|im_end|>\\n\",\n",
        "    'rejected': \"I'm an artificial intelligence language model, I don't have personal experiences or opinions. However, I can provide you with information on highly-rated and critically acclaimed films, as well as recommendations based on specific genres or themes. Would you like me to suggest some notable movies or discuss a particular genre of interest?<|im_end|>\\n\"\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3a94b01",
      "metadata": {
        "id": "a3a94b01"
      },
      "source": [
        "–¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç —Å –ø–æ–º–æ—â—å—é —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞, –æ–±—Ä–µ–∑–∞–≤ –¥–ª–∏–Ω—É –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ. –í –¥–∞—Ç–∞—Å–µ—Ç–µ –¥–æ–ª–∂–Ω—ã –æ—Å—Ç–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ ID —Ç–æ–∫–µ–Ω–æ–≤:\n",
        "```\n",
        "Dataset({\n",
        "    features: ['prompt_input_ids', 'chosen_input_ids', 'rejected_input_ids'],\n",
        "    num_rows: 10884\n",
        "})\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ad02508-e4f9-43fa-a3e6-7ecd0e2963df",
      "metadata": {
        "id": "8ad02508-e4f9-43fa-a3e6-7ecd0e2963df"
      },
      "source": [
        "–û–±—Ä–µ–∑–∞–π—Ç–µ –ø—Ä–æ–º–ø—Ç —Å–ª–µ–≤–∞, –∞ –Ω–µ —Å –∫–æ–Ω—Ü–∞. –ü–æ–¥—É–º–∞–π—Ç–µ –ø–æ—á–µ–º—É —Ç–∞–∫ –ª—É—á—à–µ. **–ù–∞–ø–∏—à–∏—Ç–µ —Å–≤–æ–π –æ—Ç–≤–µ—Ç**.\n",
        "\n",
        "    #========== TODO ==========\n",
        "    #     –í–∞—à –æ—Ç–≤–µ—Ç –∑–¥–µ—Å—å     =\n",
        "    #=========================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ab86a8b4-ba29-442b-92a9-294a9153cfe8",
      "metadata": {
        "id": "ab86a8b4-ba29-442b-92a9-294a9153cfe8"
      },
      "outputs": [],
      "source": [
        "def tokenize_row(\n",
        "    example: dict[str, str],\n",
        "    tokenizer: PreTrainedTokenizerBase,\n",
        "    max_prompt_length: int = 512,\n",
        "    max_completion_length: int | None = None,\n",
        ") -> dict[str, list[int]]:\n",
        "    \"\"\"\n",
        "    Tokenizes a single row of a dataset example for use in language model training or evaluation.\n",
        "\n",
        "    This function processes an example containing textual fields for a prompt, a chosen response,\n",
        "    and a rejected response. It tokenizes each text field using the provided tokenizer. If specified,\n",
        "    it truncates the tokenized prompt to the last `max_prompt_length` tokens and the tokenized responses\n",
        "    (chosen and rejected) to the first `max_completion_length` tokens.\n",
        "\n",
        "    Args:\n",
        "        example (dict[str, str]): A dictionary with the following keys:\n",
        "            - \"prompt\": The initial prompt text.\n",
        "            - \"chosen\": The assistant's chosen response.\n",
        "            - \"rejected\": The assistant's rejected response.\n",
        "        tokenizer (PreTrainedTokenizerBase): A tokenizer that converts text into token IDs. It must return a dictionary\n",
        "            with the key \"input_ids\" when called.\n",
        "        max_prompt_length (Optional[int], optional): Maximum number of tokens to retain for the prompt.\n",
        "            The function keeps the last `max_prompt_length` tokens. Defaults to 512.\n",
        "        max_completion_length (Optional[int], optional): Maximum number of tokens to retain for the completion\n",
        "            responses (chosen and rejected). The function keeps the first `max_completion_length` tokens.\n",
        "            If None, no truncation is applied. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        dict[str, list[int]]: A dictionary containing:\n",
        "            - \"prompt_input_ids\": The token IDs for the prompt, possibly truncated.\n",
        "            - \"chosen_input_ids\": The token IDs for the chosen response, possibly truncated.\n",
        "            - \"rejected_input_ids\": The token IDs for the rejected response, possibly truncated.\n",
        "    \"\"\"\n",
        "    prompt_ids = tokenizer.encode(example[\"prompt\"], truncation=True, max_length=max_prompt_length)\n",
        "    chosen_ids = tokenizer.encode(example[\"chosen\"], truncation=True, max_length=max_completion_length)\n",
        "    rejected_ids = tokenizer.encode(example[\"rejected\"], truncation=True, max_length=max_completion_length)\n",
        "    \n",
        "    return {\n",
        "        \"prompt_input_ids\": prompt_ids,\n",
        "        \"chosen_input_ids\": chosen_ids,\n",
        "        \"rejected_input_ids\": rejected_ids\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "902b567f",
      "metadata": {
        "id": "902b567f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prompt_input_ids': [1,\n",
              "  4093,\n",
              "  198,\n",
              "  16912,\n",
              "  28,\n",
              "  339,\n",
              "  915,\n",
              "  3680,\n",
              "  260,\n",
              "  1450,\n",
              "  1169,\n",
              "  85,\n",
              "  731,\n",
              "  457,\n",
              "  346,\n",
              "  2269,\n",
              "  357,\n",
              "  47,\n",
              "  2,\n",
              "  198,\n",
              "  1,\n",
              "  520,\n",
              "  9531,\n",
              "  198],\n",
              " 'chosen_input_ids': [10813,\n",
              "  242,\n",
              "  220,\n",
              "  12947,\n",
              "  28,\n",
              "  787,\n",
              "  339,\n",
              "  8540,\n",
              "  982,\n",
              "  17,\n",
              "  339,\n",
              "  5248,\n",
              "  11888,\n",
              "  288,\n",
              "  699,\n",
              "  28,\n",
              "  732,\n",
              "  506,\n",
              "  260,\n",
              "  1169,\n",
              "  85,\n",
              "  563,\n",
              "  47,\n",
              "  1431,\n",
              "  357,\n",
              "  253,\n",
              "  17025,\n",
              "  2644,\n",
              "  355,\n",
              "  253,\n",
              "  31404,\n",
              "  3223,\n",
              "  47,\n",
              "  1691,\n",
              "  388,\n",
              "  260,\n",
              "  9973,\n",
              "  17,\n",
              "  15107,\n",
              "  114,\n",
              "  113,\n",
              "  2,\n",
              "  198],\n",
              " 'rejected_input_ids': [57,\n",
              "  5248,\n",
              "  354,\n",
              "  6416,\n",
              "  5290,\n",
              "  1789,\n",
              "  1743,\n",
              "  28,\n",
              "  339,\n",
              "  1326,\n",
              "  982,\n",
              "  457,\n",
              "  2143,\n",
              "  2647,\n",
              "  355,\n",
              "  8428,\n",
              "  30,\n",
              "  1423,\n",
              "  28,\n",
              "  339,\n",
              "  416,\n",
              "  1538,\n",
              "  346,\n",
              "  351,\n",
              "  1096,\n",
              "  335,\n",
              "  3452,\n",
              "  29,\n",
              "  3119,\n",
              "  284,\n",
              "  9603,\n",
              "  32246,\n",
              "  9411,\n",
              "  28,\n",
              "  347,\n",
              "  876,\n",
              "  347,\n",
              "  7400,\n",
              "  1552,\n",
              "  335,\n",
              "  1678,\n",
              "  14009,\n",
              "  355,\n",
              "  5535,\n",
              "  30,\n",
              "  13651,\n",
              "  346,\n",
              "  702,\n",
              "  549,\n",
              "  288,\n",
              "  1820,\n",
              "  634,\n",
              "  7703,\n",
              "  10026,\n",
              "  355,\n",
              "  1692,\n",
              "  253,\n",
              "  1542,\n",
              "  10265,\n",
              "  282,\n",
              "  1384,\n",
              "  47,\n",
              "  2,\n",
              "  198]}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = dataset.map(\n",
        "    tokenize_row,\n",
        "    fn_kwargs={\n",
        "        \"tokenizer\": tokenizer,\n",
        "        \"max_prompt_length\": 256,\n",
        "        \"max_completion_length\": None,\n",
        "    },\n",
        "    remove_columns=[\"prompt\", \"chosen\", \"rejected\"],\n",
        ")\n",
        "\n",
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e6687c2-73a7-4ae9-972c-6603673e6401",
      "metadata": {
        "id": "4e6687c2-73a7-4ae9-972c-6603673e6401"
      },
      "source": [
        "–¢–µ–ø–µ—Ä—å –Ω–∞–¥–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å DataLoader. –î–ª—è —ç—Ç–æ–≥–æ –Ω–∞–¥–æ –Ω–∞–ø–∏—Å–∞—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–π `collate_fn` –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –¥–µ–ª–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ:\n",
        "1. –ü—Ä–∏–Ω–∏–º–∞—Ç—å –ª–∏—Å—Ç –ø—Ä–∏–º–µ—Ä–æ–≤ —Å –∫–ª—é—á–∞–º–∏ `prompt_input_ids`, `chosen_input_ids`, `rejected_input_ids`.\n",
        "2. –ü–∞–¥–¥–∏—Ç—å –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –≤ –±–∞—Ç—á–µ –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª—é—á—É. –ü–æ –∏—Ç–æ–≥—É `prompt_input_ids` –∏ `chosen_input_ids` –º–æ–≥—É—Ç –∏–º–µ—Ç—å —Ä–∞–∑–Ω—É—é –¥–ª–∏–Ω—É, —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ. –í–∞–∂–Ω–æ, —á—Ç–æ–±—ã –≤–Ω—É—Ç—Ä–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –∫–ª—é—á–µ–π –¥–ª–∏–Ω–∞ –±—ã–ª–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–∞.\n",
        "3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª—é—á–∞ —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø–∞–¥–¥–∏–Ω–≥ –º–∞—Å–∫—É —Ç–∞–∫–æ–≥–æ –∂–µ —à–µ–π–ø–∞, –≥–¥–µ 0 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–∞–¥–¥–∏–Ω–≥-—Ç–æ–∫–µ–Ω–æ–≤ –∏ 1 –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
        "\n",
        "–î–ª—è –ø–∞–¥–¥–∏–Ω–≥–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é `pad`. –í –∫–∞—á–µ—Å—Ç–≤–µ —Ç–æ–∫–µ–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `tokenizer.pad_token_id` –∏ 0 –¥–ª—è –º–∞—Å–∫–∏. **–û–ø—è—Ç—å –∂–µ, –ø–æ–¥—É–º–∞–π—Ç–µ –æ—Ç–∫—É–¥–∞ –ª—É—á—à–µ –ø–∞–¥–¥–∏—Ç—å `prompt_input_ids`?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "90431c77-694c-446b-bced-eae8124936fb",
      "metadata": {
        "id": "90431c77-694c-446b-bced-eae8124936fb"
      },
      "outputs": [],
      "source": [
        "def pad(tensors: list[torch.Tensor], padding_value: int = 0, padding_side: str = \"right\") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Pads a list of tensors to the same size along their leading dimension.\n",
        "\n",
        "    Args:\n",
        "        tensors (list[torch.Tensor]): A list of tensors to be padded.\n",
        "            All tensors in the list should be of the same type and device.\n",
        "        padding_value (int, default=0): The value used to pad the tensors.\n",
        "        padding_side (str, default=\"right\"): Specifies which side of the tensor to apply padding: either 'left' or 'right'.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A tensor containing all the padded tensors, [N; max_length]\n",
        "            where N is the number of tensors and `max_length` is the shape of the largest tensor.\n",
        "    \"\"\"\n",
        "    max_length = max(tensor.shape[0] for tensor in tensors)  # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –≤ –±–∞—Ç—á–µ\n",
        "    if padding_side == \"left\":\n",
        "        return torch.stack([torch.cat([torch.full((max_length - len(t),), padding_value, dtype=t.dtype), t]) for t in tensors])  # –ü–∞–¥–¥–∏–Ω–≥ —Å–ª–µ–≤–∞\n",
        "    else:\n",
        "        return torch.stack([torch.cat([t, torch.full((max_length - len(t),), padding_value, dtype=t.dtype)]) for t in tensors]) # –ü–∞–¥–¥–∏–Ω–≥ —Å–ø—Ä–∞–≤–∞\n",
        "\n",
        "\n",
        "def pad_collate_fn(batch: list[dict[str, torch.Tensor]], pad_token_id: int) -> dict[str, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Collates and pads a batch of tokenized examples for model input.\n",
        "\n",
        "    This function takes a batch of examples where each example is a dictionary containing\n",
        "    token IDs for the prompt, the chosen response, and the rejected response. For each field,\n",
        "    it extracts the list of token IDs, creates a corresponding attention mask (with ones for each token),\n",
        "    and then pads the sequences using a `pad` function. The prompt sequences and their attention masks\n",
        "    are padded on the left, while the chosen and rejected sequences are padded on the right (default).\n",
        "\n",
        "    Args:\n",
        "        batch (list[dict[str, torch.Tensor]]): A list of dictionaries, where each dictionary has the keys:\n",
        "            - \"prompt_input_ids\": Tensor of token IDs for the prompt.\n",
        "            - \"chosen_input_ids\": Tensor of token IDs for the chosen response.\n",
        "            - \"rejected_input_ids\": Tensor of token IDs for the rejected response.\n",
        "        pad_token_id (int): Padding value for token IDs.\n",
        "\n",
        "    Returns:\n",
        "        dict[str, torch.Tensor]: A dictionary containing the following keys with padded tensors:\n",
        "            - \"prompt_input_ids\": Padded token IDs for the prompt (padded on the left).\n",
        "            - \"prompt_attn_mask\": Padded attention mask for the prompt (padded on the left, with 1s for actual tokens).\n",
        "            - \"chosen_input_ids\": Padded token IDs for the chosen response.\n",
        "            - \"chosen_attn_mask\": Padded attention mask for the chosen response.\n",
        "            - \"rejected_input_ids\": Padded token IDs for the rejected response.\n",
        "            - \"rejected_attn_mask\": Padded attention mask for the rejected response.\n",
        "    \"\"\"\n",
        "    prompt_tensors = [torch.tensor(item[\"prompt_input_ids\"]) for item in batch]\n",
        "    chosen_tensors = [torch.tensor(item[\"chosen_input_ids\"]) for item in batch]\n",
        "    rejected_tensors = [torch.tensor(item[\"rejected_input_ids\"]) for item in batch]\n",
        "    \n",
        "    return {\n",
        "        \"prompt_input_ids\": pad(prompt_tensors, pad_token_id, \"left\"),\n",
        "        \"prompt_attn_mask\": (pad(prompt_tensors, 0, \"left\") != pad_token_id).long(),\n",
        "        \"chosen_input_ids\": pad(chosen_tensors, pad_token_id, \"right\"),\n",
        "        \"chosen_attn_mask\": (pad(chosen_tensors, 0, \"right\") != pad_token_id).long(),\n",
        "        \"rejected_input_ids\": pad(rejected_tensors, pad_token_id, \"right\"),\n",
        "        \"rejected_attn_mask\": (pad(rejected_tensors, 0, \"right\") != pad_token_id).long(),\n",
        "    }\n",
        "\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    dataset.with_format(\"torch\"),\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    collate_fn=lambda batch: pad_collate_fn(batch, tokenizer.pad_token_id),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ea248bdd",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lf/x86pzptd3pv7z45l56wggyjc0000gn/T/ipykernel_17985/2287850542.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  prompt_tensors = [torch.tensor(item[\"prompt_input_ids\"]) for item in batch]\n",
            "/var/folders/lf/x86pzptd3pv7z45l56wggyjc0000gn/T/ipykernel_17985/2287850542.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  chosen_tensors = [torch.tensor(item[\"chosen_input_ids\"]) for item in batch]\n",
            "/var/folders/lf/x86pzptd3pv7z45l56wggyjc0000gn/T/ipykernel_17985/2287850542.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  rejected_tensors = [torch.tensor(item[\"rejected_input_ids\"]) for item in batch]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'prompt_input_ids': tensor([[    1,  4093,   198,  1780,   506,   469,  4932,  1502,   282,  2477,\n",
              "            284,  1701,   536,   346,  2815,   357,    47,     2,   198,     1,\n",
              "            520,  9531,   198],\n",
              "         [    2,     2,     2,     2,     2,     1,  4093,   198,  6248,   346,\n",
              "           4640,  7956, 10026,   355,  7372,  2744,    47,     2,   198,     1,\n",
              "            520,  9531,   198]]),\n",
              " 'prompt_attn_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]]),\n",
              " 'chosen_input_ids': tensor([[26446,   314,   253,  4776,   599,   282,   957,  1029,    17,   339,\n",
              "           6737,  1643,   957,  4932,  1502,   282,  2477,   314,   641,   519,\n",
              "           4022,    30,  1385,   506,  1488,   563,   260,  5540,    28,  4122,\n",
              "           1439,   282,   357,   338,   915, 13531,   288,   549,    30,   339,\n",
              "           2606,   638,   641,   519,  4022, 12299,  1129,  4308,   351,   896,\n",
              "           4598,   284,  6825,    28,  2733,   451,  2116,    28, 48540,   386,\n",
              "          34909,   338,   506,  1759,   288,  1042,  8888,    30,   198,   198,\n",
              "          29217,    28,   339,  1042,   338,   641,   519,  4022, 21439,  3264,\n",
              "            288,   325,  2076, 20988,    30,  1069,  1129,  5895,   335,  5535,\n",
              "            282,  2606,    28,  1911, 17653,    28,   284,   639,    29, 20003,\n",
              "             28,   527,   359,   511,  1495,   339,  1510,   392,   416,   511,\n",
              "           2669,   351,    30,   657,   506,   702,   260, 12229,   359,  5914,\n",
              "           3319,   288,   469,  8664,    17,   198,   198,  2596,    28,   346,\n",
              "            699,    28,   339,  5248,   597,   253,   393, 14406,   327,   253,\n",
              "           1123,  1139, 41826,    30,  1385,   506,  3878,   702,   978,   862,\n",
              "            578,   253, 39747, 17324,   351,  2428,   418,   260,  1466,   282,\n",
              "            469,  9351,    28,  4330,  1176,  5725,   284,  8441,    30, 40303,\n",
              "            228,   198,   198,  1780,   563,   346,    28,  1239,    47,  1812,\n",
              "           1942,   282,  2477,   536,   346,  2815,    47,  5310,   346,  3658,\n",
              "            750,   725,  4936,   355, 12299, 24382,   338,   346,  2316, 37274,\n",
              "            351,    47, 15107,   232,   130,     2,   198],\n",
              "         [ 2683,   699,    28,   339,  5248,   253,  3241,   282,   253, 27689,\n",
              "             29, 27159,  6373,    28,   588,   339,  6737,   457,   288,  1643,\n",
              "           7372,  2744,   511,   260,   970,    17, 40303,   228,  1385,   506,\n",
              "           1488,   563,  2967, 15905,   281,   253,  3086,   284,  7956,   260,\n",
              "           3870,   799,   690,   655,   338,  2159, 14647,   549,   281,    30,\n",
              "           9933,    28,   351,   588,   800,  1109, 21952,  2465,   578,   665,\n",
              "             28,   357,   506,  4285,   670,  2042,   288,  1042,   253,   725,\n",
              "           1138,   288,  1859,   362,   690,    30,  1848,  1036,  1137,    28,\n",
              "            339,   536,  2815,   253,  1123,  7704,   897,  1209,   284,   965,\n",
              "            816,  2117,   585,   357,   506,   253, 36631, 32035,   355,   253,\n",
              "           7963,    29,   824,    17, 15107,   231,   140,  1073,   563,   346,\n",
              "             28,   536,   346,   457,   253, 12916,    47,     2,   198,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2]]),\n",
              " 'chosen_attn_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
              " 'rejected_input_ids': tensor([[   57,  1326,   982,   457,  2143,  8163,    28,  1285,   967,  2484,\n",
              "            288,  2477,    30,  1032,   253,  3544,  5646,    28,   339,   744,\n",
              "           2724,   288,  1538,  6987,  1096,   284,  2125,   253,  9174, 18410,\n",
              "             30,  3361,  3446,   314,   288,  4237,   284,  1538,  5161,  5928,\n",
              "             28,  2161,   670, 11974,  2143,  8428,   355,  4801,    30,   198,\n",
              "            198,  4460,    28,   339,   416,  1538,  1096,   335,  1461,  1995,\n",
              "            282,  2477,    28,   480,  4616,    28,   284,   260,  2642,  5017,\n",
              "            502,  2205,    30,  1094,   346,   457,   253,  1678,  1962,   355,\n",
              "           4234,  2484,   288,  2477,    28,   339,   736,   325,  5587,   288,\n",
              "           4237,   346,   351,   338,    30,     2,   198],\n",
              "         [   57,  5248, 11830,   339,  1326,   982,   457,  2143,  8163,   355,\n",
              "           8428,    28,  5277,   536,   339,  4555,   281, 18266,  2123,   715,\n",
              "            347,  7956, 10026,   355,  7372,  2744,    30,  3361,  3446,   314,\n",
              "            288,  1538,  1096,    28,  2988,  2029,    28,   284,  4237,   351,\n",
              "          33735,   288,   260,  1450,   282,   957,  6236,    28,  4719,   253,\n",
              "          13667,  3544, 47964,   418,   511,  1711,    30,  1094,   346,   457,\n",
              "            750,  1678,  2029,   355,  4366,   346,  6737,   702,   288,  1692,\n",
              "             28,   339,  5248,  1535,   288,  1538,  6007,    30,     2,   198,\n",
              "              2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
              "              2,     2,     2,     2,     2,     2,     2]]),\n",
              " 'rejected_attn_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "          1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1]])}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(dataloader))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628ab5cb-dd61-4f97-bd11-e790470119bf",
      "metadata": {
        "id": "628ab5cb-dd61-4f97-bd11-e790470119bf"
      },
      "source": [
        "## DPO Loss [5 –±–∞–ª–ª–æ–≤]\n",
        "\n",
        "–ù–∞—á–Ω–µ–º —Å –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–∞–º–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å. –û–Ω–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ—Å—Ç–∞—è, —Å–ª–µ–¥—É–π—Ç–µ —Ñ–æ—Ä–º—É–ª–µ –¥–æ—Å–ª–æ–≤–Ω–æ –∏ –≤—Å–µ –ø–æ–ª—É—á–∏—Ç—Å—è."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "183621d5-0d24-446b-856b-037d4075231c",
      "metadata": {
        "id": "183621d5-0d24-446b-856b-037d4075231c"
      },
      "outputs": [],
      "source": [
        "def dpo_loss(\n",
        "    chosen_logps: torch.Tensor,\n",
        "    rejected_logps: torch.Tensor,\n",
        "    ref_chosen_logps: torch.Tensor,\n",
        "    ref_rejected_logps: torch.Tensor,\n",
        "    beta: float = 0.1,\n",
        ") -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Computes the Direct Preference Optimization (DPO) loss and associated reward metrics.\n",
        "\n",
        "    Args:\n",
        "        chosen_logps (Tensor): A tensor of shape (batch_size,) containing the log-probabilities of the chosen responses.\n",
        "        rejected_logps (Tensor): A tensor of shape (batch_size,) containing the log-probabilities of the rejected responses.\n",
        "        ref_chosen_logps (Tensor): A tensor of shape (batch_size,) containing the reference log-probabilities for chosen responses.\n",
        "        ref_rejected_logps (Tensor): A tensor of shape (batch_size,) containing the reference log-probabilities for rejected responses.\n",
        "        beta (float, optional): A scaling factor applied to the differences in log-probabilities. Defaults to 0.1.\n",
        "\n",
        "    Returns:\n",
        "        tuple[Tensor, Tensor, Tensor]:\n",
        "            - loss (Tensor): The computed DPO loss as a scalar tensor.\n",
        "            - reward_accuracies (Tensor): The fraction of examples where the chosen reward exceeds the rejected reward.\n",
        "            - reward_margins (Tensor): The average difference between the chosen and rejected rewards.\n",
        "    \"\"\"\n",
        "    # –í—ã—á–∏—Å–ª—è–µ–º –Ω–∞–≥—Ä–∞–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–Ω–∏—Ü—ã –ª–æ–≥-–ø—Ä–æ–±\n",
        "    r_chosen = (chosen_logps - ref_chosen_logps) / beta\n",
        "    r_rejected = (rejected_logps - ref_rejected_logps) / beta\n",
        "\n",
        "    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É –Ω–∞–≥—Ä–∞–¥\n",
        "    reward_diff = r_chosen - r_rejected\n",
        "\n",
        "    # DPO loss —Å–æ–≥–ª–∞—Å–Ω–æ —Ñ–æ—Ä–º—É–ª–µ\n",
        "    loss = -F.logsigmoid(reward_diff).mean()\n",
        "\n",
        "    # –ú–µ—Ç—Ä–∏–∫–∏:\n",
        "    reward_accuracies = (reward_diff > 0).float().mean()  # –î–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π\n",
        "    reward_margins = reward_diff.mean()  # –°—Ä–µ–¥–Ω–∏–π –æ—Ç—Ä—ã–≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞\n",
        "\n",
        "    return loss, reward_accuracies, reward_margins\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8351081-cb90-4a02-9796-59db45944dce",
      "metadata": {
        "id": "f8351081-cb90-4a02-9796-59db45944dce"
      },
      "source": [
        "–î–ª—è —É–¥–æ–±—Å—Ç–∞ —Ç–∞–∫–∂–µ –æ–ø—Ä–µ–¥–µ–ª–∏–º –æ—Ç–¥–µ–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é —á—Ç–æ–±—ã —Å—á–∏—Ç–∞—Ç—å –ª–æ–≥-–ø—Ä–æ–±—ã –ø–æ –ª–æ–≥–∏—Ç–∞–º. –í–∞–º –Ω—É–∂–Ω–æ –≤—ã—Ç–∞—â–∏—Ç—å –ª–æ–≥–∏—Ç—ã —Ä–µ–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ù–µ –∑–∞–±—É–¥—å—Ç–µ –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞—Ç—å –ª–æ–≥-–ø—Ä–æ–±—ã –ø—Ä–æ–º–ø—Ç–∞ –ø–µ—Ä–µ–¥ –∞–≥–≥—Ä–µ–≥–∞—Ü–∏–µ–π. –ú–∞—Å–∫–∞ –∑–¥–µ—Å—å —É–∂–µ –¥–∞–Ω–∞.\n",
        "\n",
        "–ü–æ–¥—Å–∫–∞–∑–∫–∞: –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø–æ–¥—É–º–∞–π—Ç–µ –∫–∞–∫ —Å–æ–æ—Ç–Ω–æ—Å—è—Ç—Å—è –ª–æ–≥–ø—Ä–æ–±—ã –∏ –Ω–∞—Å—Ç–æ—è—â–∏–µ –∏–Ω–¥–µ–∫—Å—ã, –∏–Ω–∞—á–µ —Ä–∏—Å–∫—É–µ—Ç–µ –æ—à–∏–±–∏—Ç—å—Å—è –Ω–∞ 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c81deee5-e71c-4709-b766-ffcb7ab365c8",
      "metadata": {
        "id": "c81deee5-e71c-4709-b766-ffcb7ab365c8"
      },
      "outputs": [],
      "source": [
        "def get_log_prob(logits: torch.Tensor, labels: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Computes the log probability for each sequence in a batch.\n",
        "\n",
        "    Args:\n",
        "        logits (Tensor): A tensor of shape [batch_size, seq_len, vocab_size]\n",
        "            representing the model's output logits.\n",
        "        labels (Tensor): A tensor of shape [batch_size, seq_len] containing the target token indices.\n",
        "        mask (Tensor): A tensor of shape [batch_size, seq_len] indicating which tokens to include\n",
        "            in the log probability (e.g., 1 for valid tokens and 0 for padding or prompt).\n",
        "\n",
        "    Returns:\n",
        "        Tensor: A tensor of shape [batch_size,] containing the log probability for each sequence.\n",
        "    \"\"\"\n",
        "    # –ü–æ–ª—É—á–∞–µ–º log_softmax –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –∏–∑–º–µ—Ä–µ–Ω–∏—é (vocab_size)\n",
        "    log_probs = F.log_softmax(logits, dim=-1)\n",
        "\n",
        "    # –í—ã–±–∏—Ä–∞–µ–º –ª–æ–≥-–ø—Ä–æ–±—ã —Ç–æ–ª—å–∫–æ –¥–ª—è —Ü–µ–ª–µ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ (labels)\n",
        "    selected_log_probs = log_probs.gather(dim=-1, index=labels.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "    # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Å–∫—É, –æ–±–Ω—É–ª—è—è –ª–æ–≥-–ø—Ä–æ–±—ã –¥–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤ –∏ padding'–∞\n",
        "    masked_log_probs = selected_log_probs * mask\n",
        "\n",
        "    # –°—É–º–º–∏—Ä—É–µ–º –ª–æ–≥-–ø—Ä–æ–±—ã –ø–æ –≤—Å–µ–º —Ç–æ–∫–µ–Ω–∞–º –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
        "    return masked_log_probs.sum(dim=-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d528b248-2040-4605-b20a-6e43269a531c",
      "metadata": {
        "id": "d528b248-2040-4605-b20a-6e43269a531c"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ DPO [5 –±–∞–ª–ª–æ–≤]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "597a061a-def0-4dfe-ac5a-309044b08a79",
      "metadata": {
        "id": "597a061a-def0-4dfe-ac5a-309044b08a79"
      },
      "source": [
        "–ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏ –¥–∞—Ç–∞—Å–µ—Ç —Å –Ω—É–ª—è.\n",
        "–î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –æ–≥—Ä–∞–Ω–∏—á–∏–º—Å—è –æ–±—ã—á–Ω—ã–º —Ü–∏–∫–ª–æ–º, –±–µ–∑ –∫–æ–Ω—Ñ–∏–≥–æ–≤, –∫–ª–∞—Å—Å–æ–≤ –∏ –ø—Ä–æ—á–µ–≥–æ.\n",
        "–í—ã –º–æ–∂–µ—Ç–µ –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å –∫–∞–∫ —É–¥–æ–±–Ω–æ –≤–∞–º, –≥–ª–∞–≤–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å.\n",
        "\n",
        "–í—Å–µ –Ω—É–∂–Ω–æ–µ —É –Ω–∞—Å —É–∂–µ –µ—Å—Ç—å, –æ—Å—Ç–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å —ç—Ç–æ –≤—Å–µ –≤–º–µ—Å—Ç–µ.\n",
        "–î–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –ª–æ–≥–ø—Ä–æ–±—ã –¥–ª—è –ø—Ä–æ–º–ø—Ç+–≤—ã–±—Ä–∞–Ω–Ω—ã–π –∏ –ø—Ä–æ–º–ø—Ç+–æ—Ç–≤–µ—Ä–≥–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç—ã.\n",
        "–ù–µ –∑–∞–±—ã—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–æ–±—Ä–∞—Ç—å –º–∞—Å–∫—É –¥–ª—è –ª–æ—Å—Å–∞.\n",
        "–í –∫–æ–Ω—Ü–µ –æ–±—Ä–µ–∑–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –≤—Ö–æ–¥—ã –¥–ª—è –º–æ–¥–µ–ª–∏ –¥–æ `MAX_SEQ_LEN` (—Å –Ω—É–∂–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω—ã!).\n",
        "\n",
        "–û–±—É—á–µ–Ω–∏–µ –∑–∞–Ω–∏–º–∞–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ —á–∞—Å –Ω–∞ Colab T4 GPU, 2 –º–∏–Ω—É—Ç –Ω–∞ H100. –í Colab –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å float16 –∏ AMP.\n",
        "–ù–µ –∑–∞–±—É–¥—å—Ç–µ –ø—Ä–æ —Å–∫–µ–π–ª–∏–Ω–≥. –î–ª—è bf16 –æ–Ω –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω.\n",
        "\n",
        "**NB**: –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Kaggle Notebooks, —Ç.–∫. –æ–Ω–∏ –Ω–µ –≤—ã–ª–µ—Ç–∞—é—Ç –µ—Å–ª–∏ –¥–æ–ª–≥–æ –Ω–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å —Å —Ç–µ—Ç—Ä–∞–¥–∫–æ–π. –ò—Ö –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–ª—è—Ç—å –Ω–∞ —á–∞—Å –±–µ–∑ –±–æ—è–∑–Ω–∏, —á—Ç–æ –æ–Ω–∏ —É–ø–∞–¥—É—Ç."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2290d52a-a5c3-4dab-a448-94a9cddd4e46",
      "metadata": {
        "id": "2290d52a-a5c3-4dab-a448-94a9cddd4e46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 'mps' device\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 16  # in colab make it smaller, or implement grad accumulation\n",
        "NUM_EPOCHS = 1\n",
        "LR = 5e-5\n",
        "MAX_SEQ_LEN = 1024  # this also can be adjusted\n",
        "MAX_PROMPT_LEN = 256 # this also can be adjusted\n",
        "MAX_COMPLETION_LEN = None\n",
        "BETA = 1.0\n",
        "\n",
        "# –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –≤–∞–º —Ö–æ—á–µ—Ç—Å—è –ª–æ–≥–≥–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ W&B\n",
        "ENABLE_WANDB = False\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    DEVICE = \"mps\"\n",
        "else:\n",
        "    DEVICE = \"cpu\"\n",
        "print(f\"Using '{DEVICE}' device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "2d965a85-ae7b-4b88-9c62-aaebe54c4b2c",
      "metadata": {
        "id": "2d965a85-ae7b-4b88-9c62-aaebe54c4b2c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af03c6bdf8ed419f9c0795231695928c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch:   0%|          | 0/2721 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lf/x86pzptd3pv7z45l56wggyjc0000gn/T/ipykernel_17985/2287850542.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  prompt_tensors = [torch.tensor(item[\"prompt_input_ids\"]) for item in batch]\n",
            "/var/folders/lf/x86pzptd3pv7z45l56wggyjc0000gn/T/ipykernel_17985/2287850542.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  chosen_tensors = [torch.tensor(item[\"chosen_input_ids\"]) for item in batch]\n",
            "/var/folders/lf/x86pzptd3pv7z45l56wggyjc0000gn/T/ipykernel_17985/2287850542.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  rejected_tensors = [torch.tensor(item[\"rejected_input_ids\"]) for item in batch]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "MPS backend out of memory (MPS allocated: 8.45 GB, other allocations: 604.67 MB, max allowed: 9.07 GB). Tried to allocate 38.43 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[28], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# 2. –ü–æ–ª—É—á–∞–µ–º –ª–æ–≥–∏ –¥–ª—è –º–æ–¥–µ–ª–∏ –∏ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–π –º–æ–¥–µ–ª–∏\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 72\u001b[0m     ref_chosen_logits \u001b[38;5;241m=\u001b[39m \u001b[43mref_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchosen_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchosen_attention_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     73\u001b[0m     ref_rejected_logits \u001b[38;5;241m=\u001b[39m ref_model(rejected_input_ids, attention_mask\u001b[38;5;241m=\u001b[39mrejected_attention_mask)\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     75\u001b[0m chosen_logits \u001b[38;5;241m=\u001b[39m model(chosen_input_ids, attention_mask\u001b[38;5;241m=\u001b[39mchosen_attention_mask)\u001b[38;5;241m.\u001b[39mlogits\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:853\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:601\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    590\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    591\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m         position_embeddings,\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 601\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:343\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:299\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m         attention_interface \u001b[38;5;241m=\u001b[39m ALL_ATTENTION_FUNCTIONS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_attn_implementation]\n\u001b[0;32m--> 299\u001b[0m attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mattention_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    311\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mo_proj(attn_output)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/integrations/sdpa_attention.py:54\u001b[0m, in \u001b[0;36msdpa_attention_forward\u001b[0;34m(module, query, key, value, attention_mask, dropout, scaling, is_causal, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(is_causal, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     52\u001b[0m     is_causal \u001b[38;5;241m=\u001b[39m is_causal\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 54\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 8.45 GB, other allocations: 604.67 MB, max allowed: 9.07 GB). Tried to allocate 38.43 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
          ]
        }
      ],
      "source": [
        "set_seed(42)\n",
        "\n",
        "if ENABLE_WANDB:\n",
        "    wandb.init(project=\"hw2-rlhf\", group=\"dpo\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    attn_implementation=\"sdpa\",\n",
        "    # only if you have A/H100 GPU\n",
        "    # torch_dtype=torch.bfloat16,\n",
        "    device_map=DEVICE,\n",
        ")\n",
        "model.train()\n",
        "disable_dropout_in_model(model)\n",
        "\n",
        "ref_model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    attn_implementation=\"sdpa\",\n",
        "    # only if you have A/H100 GPU\n",
        "    # torch_dtype=torch.bfloat16,\n",
        "    device_map=DEVICE,\n",
        ")\n",
        "ref_model.eval()\n",
        "disable_dropout_in_model(ref_model)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "dataset = load_dataset(DATASET_ID, split=\"train\")\n",
        "dataset = dataset.map(apply_chat_template, fn_kwargs={\"tokenizer\": tokenizer})\n",
        "dataset = dataset.map(\n",
        "    tokenize_row,\n",
        "    fn_kwargs={\n",
        "        \"tokenizer\": tokenizer,\n",
        "        \"max_prompt_length\": MAX_PROMPT_LEN,\n",
        "        \"max_completion_length\": MAX_COMPLETION_LEN,\n",
        "    },\n",
        "    remove_columns=[\"prompt\", \"chosen\", \"rejected\"],\n",
        ")\n",
        "dataloader = DataLoader(\n",
        "    dataset.with_format(\"torch\"),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    pin_memory=False,\n",
        "    collate_fn=partial(pad_collate_fn, pad_token_id=tokenizer.pad_token_id),\n",
        ")\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    losses, accs, margins = [], [], []\n",
        "\n",
        "    pbar = tqdm(dataloader, desc=\"Epoch\", leave=False)\n",
        "    for batch in pbar:\n",
        "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "\n",
        "        # 1. –°–æ–µ–¥–∏–Ω—è–µ–º –ø—Ä–æ–º–ø—Ç —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –∏ –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏\n",
        "        chosen_input_ids = torch.cat([batch[\"prompt_input_ids\"], batch[\"chosen_input_ids\"]], dim=-1)\n",
        "        rejected_input_ids = torch.cat([batch[\"prompt_input_ids\"], batch[\"rejected_input_ids\"]], dim=-1)\n",
        "\n",
        "        chosen_attention_mask = torch.cat([batch[\"prompt_attn_mask\"], batch[\"chosen_attn_mask\"]], dim=-1)\n",
        "        rejected_attention_mask = torch.cat([batch[\"prompt_attn_mask\"], batch[\"rejected_attn_mask\"]], dim=-1)\n",
        "\n",
        "        # –û–±—Ä–µ–∑–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–æ MAX_SEQ_LEN\n",
        "        chosen_input_ids = chosen_input_ids[:, :MAX_SEQ_LEN]\n",
        "        rejected_input_ids = rejected_input_ids[:, :MAX_SEQ_LEN]\n",
        "\n",
        "        chosen_attention_mask = chosen_attention_mask[:, :MAX_SEQ_LEN]\n",
        "        rejected_attention_mask = rejected_attention_mask[:, :MAX_SEQ_LEN]\n",
        "\n",
        "        # 2. –ü–æ–ª—É—á–∞–µ–º –ª–æ–≥–∏ –¥–ª—è –º–æ–¥–µ–ª–∏ –∏ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
        "        with torch.no_grad():\n",
        "            ref_chosen_logits = ref_model(chosen_input_ids, attention_mask=chosen_attention_mask).logits\n",
        "            ref_rejected_logits = ref_model(rejected_input_ids, attention_mask=rejected_attention_mask).logits\n",
        "\n",
        "        chosen_logits = model(chosen_input_ids, attention_mask=chosen_attention_mask).logits\n",
        "        rejected_logits = model(rejected_input_ids, attention_mask=rejected_attention_mask).logits\n",
        "\n",
        "        # 3. –ü–æ–ª—É—á–∞–µ–º –ª–æ–≥-–ø—Ä–æ–±—ã\n",
        "        chosen_logps = get_log_prob(chosen_logits, chosen_input_ids, chosen_attention_mask)\n",
        "        rejected_logps = get_log_prob(rejected_logits, rejected_input_ids, rejected_attention_mask)\n",
        "\n",
        "        ref_chosen_logps = get_log_prob(ref_chosen_logits, chosen_input_ids, chosen_attention_mask)\n",
        "        ref_rejected_logps = get_log_prob(ref_rejected_logits, rejected_input_ids, rejected_attention_mask)\n",
        "\n",
        "        # 4. –í—ã—á–∏—Å–ª—è–µ–º –ª–æ—Å—Å\n",
        "        loss, reward_accuracies, reward_margins = dpo_loss(\n",
        "            chosen_logps, rejected_logps, ref_chosen_logps, ref_rejected_logps, beta=BETA\n",
        "        )\n",
        "\n",
        "        # 5. –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        accs.append(reward_accuracies.item())\n",
        "        margins.append(reward_margins.item())\n",
        "        pbar.set_postfix({\"Reward margins\": np.mean(margins), \"Reward acc\": np.mean(accs)})\n",
        "\n",
        "        if ENABLE_WANDB:\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"loss\": loss.item(),\n",
        "                    \"train-reward-margins\": reward_margins.item(),\n",
        "                    \"train-reward-accuracy\": reward_accuracies.item(),\n",
        "                    \"epoch\": epoch,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    pbar.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef3e6ab0-9437-473e-abcd-0dd33c974570",
      "metadata": {
        "id": "ef3e6ab0-9437-473e-abcd-0dd33c974570"
      },
      "source": [
        "–í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è reward margins –∏ accuracy –¥–æ–ª–∂–Ω—ã –±—ã–ª–∏ —Ä–∞—Å—Ç–∏. –î–∞–≤–∞–π—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏–º —á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b739545-0c57-4ede-a874-788236b38420",
      "metadata": {
        "editable": true,
        "id": "8b739545-0c57-4ede-a874-788236b38420",
        "tags": []
      },
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What's your morning routine like?\"}]\n",
        "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=256, do_sample=True)\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "init_generated_ids = ref_model.generate(model_inputs.input_ids, max_new_tokens=256, do_sample=True)\n",
        "init_response = tokenizer.batch_decode(init_generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "print(\"======== BEFORE TUNING ========\")\n",
        "print(init_response)\n",
        "print()\n",
        "\n",
        "print(\"======== AFTER TUNING ========\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb73140",
      "metadata": {
        "id": "cbb73140"
      },
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –Ω–∞ —Ö–∞–±\n",
        "\n",
        "model.push_to_hub(f\"{REPO_NAME}-dpo\", private=True)\n",
        "tokenizer.push_to_hub(f\"{REPO_NAME}-dpo\", private=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84318ed4-e3db-4151-88fc-cb00755e6b63",
      "metadata": {
        "id": "84318ed4-e3db-4151-88fc-cb00755e6b63"
      },
      "source": [
        "# –ß–∞—Å—Ç—å 2: PPO –∏ TRL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcce2878-10bb-4dd9-9313-137528a0d1b6",
      "metadata": {
        "id": "fcce2878-10bb-4dd9-9313-137528a0d1b6"
      },
      "source": [
        "–í—Ç–æ—Ä–∞—è —á–∞—Å—Ç—å –±—É–¥–µ—Ç —Å–∏–ª—å–Ω–æ –ø—Ä–æ—â–µ –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∞ –Ω–∞ —Ç–æ, —á—Ç–æ–±—ã –ø–æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è —Å —Å–∞–º–æ–π –ø–æ–ø—É–ª—è—Ä–Ω–æ–π –±–∏–±–ª–æ—Ç–µ–∫–æ–π –¥–ª—è –∞–ª–∞–π–º–µ–Ω—Ç–∞ –æ—Ç huggingface - [TRL](https://huggingface.co/docs/trl/v0.15.0/index). C –ø–æ–º–æ—â—å—é TRL –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –æ–±—É—á–∏—Ç—å PPO, –∞ –¥–ª—è —ç—Ç–æ–≥–æ –≤–Ω–∞—á–∞–ª–µ –æ–±—É—á–∏—Ç—å Reward Model.\n",
        "\n",
        "**–õ–∏—Ä–∏—á–µ—Å–∫–æ–µ –æ—Ç—Å—Ç—É–ø–ª–µ–Ω–∏–µ**: PPO –∏–º–µ–µ—Ç –ø–∞—Ä–∞–¥–æ–∫—Å–∞–ª—å–Ω—É—é —Ä–µ–ø—É—Ç–∞—Ü–∏—é. –° –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–Ω—ã –≤ RL –æ–Ω —Å—á–∏—Ç–∞–µ—Ç—Å—è —á—É—Ç—å –ª–∏ –Ω–µ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–º –ø—Ä–∏–º–µ–Ω–∏–º—ã–º (–¥–æ —Å–∏—Ö –ø–æ—Ä) –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–º, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–≤–æ–¥–∏—Ç—Å—è —Å –ø–æ–ª-–ø–∏–Ω–∫–∞ –∏ –Ω–∞ –ª—é–±–æ–π –∑–∞–¥–∞—á–µ. –û—Å–Ω–æ–≤–Ω–æ–π –±–æ—Ç—Ç–ª–Ω–µ–∫ –¥–ª—è –Ω–µ–≥–æ - –¥–∞–Ω–Ω—ã–µ, —á–µ–º –±—ã—Å—Ç—Ä–µ–µ —Å–∏–º—É–ª—è—Ç–æ—Ä, —Ç–∞–º –±–æ–ª—å—à–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å, —á—Ç–æ –æ–Ω –≤–∞—à—É –∑–∞–¥–∞—á—É —Ä–µ—à–∏—Ç. –ü—Ä–∏–º–µ—Ä–æ–≤ –º–Ω–æ–≥–æ - —Ç–∞–∫ —Ä–µ—à–∏–ª–∏ Dota 2 –∏–ª–∏ Minecraft. –° –¥—Ä—É–≥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, —É –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –∫—Ä–∞–π–Ω–µ –¥—É—Ä–Ω–∞—è —Ä–µ–ø—É—Ç–∞—Ü–∏—è –≤ –ø–ª–∞–Ω–µ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å –Ω—É–ª—è, —Ç.–∫. –µ—Å—Ç—å –º–Ω–æ–≥–æ –≤–∞–∂–Ω—ã—Ö –∏ –º–∞–ª–µ–Ω—å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø—Ä–∏–≤–µ–¥—É—Ç –∫ –Ω–µ–∑–∞–º–µ—Ç–Ω–æ–º—É, –Ω–æ –∫—Ä–∞–π–Ω–µ —Å—Ç—Ä–∞–Ω–Ω–æ–º—É –ø–æ–≤–µ–¥–µ–Ω–∏—é. –î–µ–±–∞–≥–∞—Ç—å —ç—Ç–æ –æ—á–µ–Ω—å —Å–ª–æ–∂–Ω–æ, [—á–µ–≥–æ —Å—Ç–æ–∏—Ç —Ç–æ–ª—å–∫–æ —ç—Ç–æ—Ç —Å–ø–∏—Å–æ–∫](https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/) –∏ [—Ç–∞–∫–æ–π –∂–µ –¥–ª—è —É–∂–µ RLHF](https://huggingface.co/blog/the_n_implementation_details_of_rlhf_with_ppo), –ø—Ä–∏—á–µ–º —á–∞—Å—Ç–æ —Ç—Ä—é–∫–∏ –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è –º–µ–∂–¥—É –¥–æ–º–µ–Ω–∞–º–∏. –ë–æ–ª–µ–µ —Ç–æ–≥–æ, –∫–∞–∫ —Ä–∞–∑ –∏–∑-–∑–∞ —ç—Ç–æ–≥–æ –µ—Å–ª–∏ –≤—ã –∑–∞–≥—É–≥–ª–∏—Ç–µ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏–∏ PPO —Å –Ω—É–ª—è, —Å –±–æ–ª—å—à–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –±–æ–ª—å—à–∞—è —á–∞—Å—Ç—å –±—É–¥–µ—Ç —Å –æ—à–∏–±–∫–∞–º–∏.\n",
        "\n",
        "–ü–æ—ç—Ç–æ–º—É –∫–æ–¥–∏—Ç—å PPO –±–µ–∑ —Ç–µ—Å–Ω–æ–≥–æ –∑–Ω–∞–∫–æ–º—Å—Ç–≤–∞ –∏ –æ–ø—ã—Ç–∞ –≤ RL –∫—Ä–∞–π–Ω–µ –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è. –î–ª—è RLHF –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TRL –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏, –¥–ª—è RL –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å [Sample-Factory](https://github.com/alex-petrenko/sample-factory)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1616be4-4106-49a6-8c7f-155081d7263d",
      "metadata": {
        "id": "d1616be4-4106-49a6-8c7f-155081d7263d"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ Reward Model [2 –±–∞–ª–ª]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "323184d8-e45a-42a7-aa7a-a59d9ecc50ae",
      "metadata": {
        "id": "323184d8-e45a-42a7-aa7a-a59d9ecc50ae"
      },
      "source": [
        "–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç DPO, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–≤–æ–¥–∏—Ç –∞–ø–¥–µ–π—Ç —è–≤–Ω–æ, —É–±–∏—Ä–∞—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –≤ –Ω–∞–≥—Ä–∞–¥–µ, –¥–ª—è PPO –Ω–∞–≥—Ä–∞–¥–∞ –Ω—É–∂–Ω–∞, –∞ –∑–Ω–∞—á–∏—Ç –∫—Ç–æ-—Ç–æ –¥–æ–ª–∂–µ–Ω –µ–µ –≤—ã–¥–∞–≤–∞—Ç—å. –í –æ–±—â–µ–º —Å–ª—É—á–∞–µ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∫–∞–∫–∞—è-—Ç–æ –ø—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –Ω–∞–ø—Ä–∏–º–µ—Ä —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º. –î–ª—è PPO, TRL –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–∞–≥—Ä–∞–¥—ã –æ—Ç –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–∫ (–Ω–æ —ç—Ç–æ –ø–æ–ø—Ä–∞–≤—è—Ç –≤ –±—É–¥—É—â–µ–º).\n",
        "\n",
        "–í–æ–∑—å–º–µ–º —Ç–æ—Ç –∂–µ –¥–∞—Ç–∞—Å–µ—Ç –∏ –ø–æ–ø—Ä–æ–±—É–µ–º –æ–±—É—á–∏—Ç—å —Å–∞–º–∏. –î–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è preference dataset with implicit prompt ([—Å–º. –ø—Ä–∏–º–µ—Ä—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏](https://huggingface.co/docs/trl/main/dataset_formats)). –¢–æ –µ—Å—Ç—å –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ç–æ–ª—å–∫–æ –¥–≤–µ –∫–æ–ª–æ–Ω–∫–∏: chosen, rejected, –∫–∞–∂–¥–∞—è —Å–æ–¥–µ—Ä–∂–∞—è—â–∞—è –≤ —Å–µ–±–µ –ø—Ä–æ–º–ø—Ç. –ü–æ –∞–Ω–∞–ª–æ–≥–∏–∏, —ç—Ç–æ –≤—Å–µ –Ω–∞–¥–æ –ø—Ä–∏–≤–µ—Å—Ç–∏ –≤ —Ç–µ–º–ø–ª–µ–π—Ç —á–∞—Ç–∞.\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä:\n",
        "```python\n",
        "## Implicit prompt\n",
        "preference_example = {\n",
        "    \"chosen\": [\n",
        "        {\"role\": \"user\", \"content\": \"What color is the sky?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"It is blue.\"}\n",
        "    ],\n",
        "    \"rejected\": [\n",
        "        {\"role\": \"user\", \"content\": \"What color is the sky?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"It is green.\"}\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "–ü–æ–¥—Ä–æ–±–Ω–µ–µ –ø—Ä–æ –ª–æ—Å—Å –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç—Å—è [—Ç—É—Ç](https://rlhfbook.com/c/07-reward-models.html). TRL –≤—Å–µ —Å–¥–µ–ª–∞–µ—Ç –∑–∞ –≤–∞—Å."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1337a76-ab6e-47f6-8d14-3430234b9858",
      "metadata": {
        "id": "e1337a76-ab6e-47f6-8d14-3430234b9858"
      },
      "outputs": [],
      "source": [
        "def to_implicit_prompt_preferences(example: dict[str, str]) -> dict[str, list[dict[str, str]]]:\n",
        "    \"\"\"\n",
        "    Converts an example into implicit prompt preferences format.\n",
        "\n",
        "    Args:\n",
        "        example (dict[str, str]): A dictionary with the following keys:\n",
        "            - \"prompt\": The user's input prompt.\n",
        "            - \"chosen\": The assistant's chosen response.\n",
        "            - \"rejected\": The assistant's rejected response.\n",
        "\n",
        "    Returns:\n",
        "        dict[str, list[dict[str, str]]]: A dictionary containing:\n",
        "            - \"chosen\": A list of messages forming the conversation for the chosen response.\n",
        "            - \"rejected\": A list of messages forming the conversation for the rejected response.\n",
        "    \"\"\"\n",
        "    # ========== TODO ==========\n",
        "    #      –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å      =\n",
        "    # ==========================\n",
        "    todo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f7c44a5-82bf-4446-940a-e53bbd50d65d",
      "metadata": {
        "id": "4f7c44a5-82bf-4446-940a-e53bbd50d65d"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(DATASET_ID, split=\"train\")\n",
        "dataset = dataset.map(to_implicit_prompt_preferences, remove_columns=[\"prompt\"])\n",
        "dataset = dataset.train_test_split(train_size=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "495a42f6-2acc-4382-84ad-444d689892a2",
      "metadata": {
        "id": "495a42f6-2acc-4382-84ad-444d689892a2"
      },
      "source": [
        "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±—É–¥–µ–º —Ç—É –∂–µ –º–æ–¥–µ–ª—å, –æ–±—É—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π –ø–æ–≤–µ—Ä—Ö. –î–ª—è –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `AutoModelForSequenceClassification`. –û–±—É—á–∏—Ç–µ —Ä–µ–≤–∞—Ä–¥ –º–æ–¥–µ–ª—å —Å –ø–æ–º–æ—â—å `RewardConfig` –∏ `RewardTrainer`. –û–¥–Ω–æ–π —ç–ø–æ—Ö–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ (–¥–∞–∂–µ –º–µ–Ω—å—à–µ). –î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –ø–æ–¥–≥—Ä—É–∑–∏—Ç–µ –ø–æ–ª—É—á–∏–≤—à—É—é—Å—è –º–æ–¥–µ–ª—å –Ω–∞ —Ö–∞–±."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d5562eb-d49c-41c7-b9b6-8640da8c39dc",
      "metadata": {
        "id": "4d5562eb-d49c-41c7-b9b6-8640da8c39dc",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "# –í–∞–∂–Ω–æ, —á—Ç–æ–±—ã —Ç—Ä–µ–Ω–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ—Ç—Ä–∞–±–æ—Ç–∞–ª –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏.\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# ========== TODO ==========\n",
        "#      –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å      =\n",
        "# ==========================\n",
        "reward_model = todo()\n",
        "reward_model.train()\n",
        "reward_model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "reward_config = RewardConfig(\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=16,\n",
        "    max_length=1024,\n",
        "    disable_dropout=True,\n",
        "    learning_rate=3e-4,\n",
        "    seed=42,\n",
        "    logging_steps=25,\n",
        "    report_to=\"wandb\" if ENABLE_WANDB else \"none\",\n",
        ")\n",
        "reward_trainer = RewardTrainer(\n",
        "    model=reward_model,\n",
        "    processing_class=tokenizer,\n",
        "    args=reward_config,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        ")\n",
        "\n",
        "reward_trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9af43201-f883-4399-9673-bca566decbc8",
      "metadata": {
        "id": "9af43201-f883-4399-9673-bca566decbc8"
      },
      "source": [
        "–ù–∞–≥—Ä–∞–¥–∞ –¥–ª—è chosen –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤—ã—à–µ —á–µ–º –¥–ª—è rejected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06962fb8-1cfb-4c0f-bf35-dda4fb2b4037",
      "metadata": {
        "id": "06962fb8-1cfb-4c0f-bf35-dda4fb2b4037"
      },
      "outputs": [],
      "source": [
        "inputs_chosen = tokenizer.apply_chat_template(dataset[\"test\"][0][\"chosen\"], tokenize=False)\n",
        "inputs_chosen = tokenizer(inputs_chosen, return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "inputs_rejected = tokenizer.apply_chat_template(dataset[\"test\"][0][\"rejected\"], tokenize=False)\n",
        "inputs_rejected = tokenizer(inputs_rejected, return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "score_chosen = reward_model(**inputs_chosen).logits[0].cpu().detach()\n",
        "score_rejected = reward_model(**inputs_rejected).logits[0].cpu().detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e43f430-3a8c-4a07-bc6e-ab934963921d",
      "metadata": {
        "id": "9e43f430-3a8c-4a07-bc6e-ab934963921d"
      },
      "outputs": [],
      "source": [
        "score_chosen, score_rejected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dec6bca3",
      "metadata": {
        "id": "dec6bca3"
      },
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∏–º reward –º–æ–¥–µ–ª—å –Ω–∞ —Ö–∞–±\n",
        "\n",
        "reward_trainer.push_to_hub(f\"{REPO_NAME}-reward-model\", dataset_name=DATASET_ID, private=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4c35fb9-2aac-408b-aff9-da6251dc7c0f",
      "metadata": {
        "id": "c4c35fb9-2aac-408b-aff9-da6251dc7c0f"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ PPO [4 –±–∞–ª–ª–∞]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b2e2a40-589b-42bf-bf15-bb10bb0e84cd",
      "metadata": {
        "id": "9b2e2a40-589b-42bf-bf15-bb10bb0e84cd"
      },
      "source": [
        "**WARN**: TRL –Ω–µ–¥–∞–≤–Ω–æ —Å–º–µ—Ä–∂–∏–ª–∏ –±–æ–ª—å—à–æ–π —Ä–µ—Ñ–∞–∫—Ç–æ—Ä PPO, –∑–∞–±—ã–≤ –æ–±–Ω–æ–≤–∏—Ç—å –≤—Å—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –∏ –ø—Ä–∏–º–µ—Ä—ã ü•¥ü•¥ü•¥. –î–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ —Å–º–æ—Ç—Ä–∏—Ç–µ –≤ –∫–æ–¥, –∞ –Ω–µ –≤ –¥–æ–∫–º–µ–Ω—Ç–∞—Ü–∏—é. –ï—Å–ª–∏ –≤–∞–º –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ –∑–Ω–∞—Ç—å –≤–∏–Ω–æ–≤–Ω—ã—Ö –≤ –ª–∏—Ü–æ:\n",
        "\n",
        "<a href=\"https://ibb.co/zTFL4GTt\"><img src=\"https://i.ibb.co/1tMpm8t4/Screenshot-2025-02-13-at-17-40-48.png\" alt=\"\" border=\"0\" /></a>\n",
        "\n",
        "–î–ª—è PPO –Ω–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è —Ç–æ—Ç –∂–µ –¥–∞—Ç–∞—Å–µ—Ç, –Ω–æ —É–∂–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Ç–æ–ª—å–∫–æ prompt. –ü—Ä–∏–≤–µ–¥–∏—Ç–µ prompt –≤ —á–∞—Ç —Ç–µ–º–ø–ª–µ–π—Ç –∏ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–π—Ç–µ (`tokenizer.apply_chat_template`). –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å.\n",
        "\n",
        "–í –∫–∞—á–µ—Å—Ç–≤–µ `policy`, `ref_policy` –ø–æ–¥–≥—Ä—É–∑–∏—Ç–µ SmolLM2-135M-Instruct, –≤ –∫–∞—á–µ—Å—Ç–≤–µ `reward_model`, `value_model` —Å–≤–æ—é –æ–±—É—á–µ–Ω–Ω—É—é —Ä–µ–≤–∞—Ä–¥ –º–æ–¥–µ–ª—å. –î–ª—è –æ–±—É—á–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `PPOConfig` –∏ `PPOTrainer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de68e7e9-c107-46e8-b4f4-f0118af36036",
      "metadata": {
        "id": "de68e7e9-c107-46e8-b4f4-f0118af36036",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, padding_side=\"left\")\n",
        "tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
        "\n",
        "# ========== TODO ==========\n",
        "#      –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å       =\n",
        "# ==========================\n",
        "value_model = todo()\n",
        "reward_model = todo()\n",
        "policy = todo()\n",
        "ref_policy = todo()\n",
        "\n",
        "\n",
        "def tokenize(example, tokenizer):\n",
        "    input_ids = todo()\n",
        "    return {\"input_ids\": input_ids}\n",
        "\n",
        "\n",
        "dataset = load_dataset(DATASET_ID, split=\"train\")\n",
        "dataset = dataset.remove_columns([\"chosen\", \"rejected\"])\n",
        "dataset = dataset.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer}, remove_columns=dataset.column_names)\n",
        "dataset = dataset.train_test_split()\n",
        "\n",
        "training_args = todo()\n",
        "trainer = todo()\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abeaee5e-8429-48bf-a35b-3addfdb10efb",
      "metadata": {
        "id": "abeaee5e-8429-48bf-a35b-3addfdb10efb"
      },
      "source": [
        "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤ –æ—Ç–≤–µ—Ç–∞—Ö. –í–ø–æ–ª–Ω–µ –≤–µ—Ä–æ—è—Ç–Ω–æ, —á—Ç–æ –≤—ã –Ω–µ —É–≤–∏–¥–∏—Ç–µ —Ç–∞–∫–æ–≥–æ —Å–∏–ª—å–Ω–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞–∫ –ø–æ—Å–ª–µ DPO. PPO —Ç—Ä–µ–±—É–µ—Ç –≥–æ—Ä–∞–∑–¥–æ –±–æ–ª—å—à–µ —Ä–µ—Å—É—Ä—Å–æ–≤, –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –≤ —Ü–µ–ª–æ–º –Ω–µ —Ç–∞–∫ —Å—Ç–∞–±–∏–ª–µ–Ω."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f399f65-81f2-4867-a776-09be56d4f7e1",
      "metadata": {
        "id": "5f399f65-81f2-4867-a776-09be56d4f7e1"
      },
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What's your morning routine like?\"}]\n",
        "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "generated_ids = policy.generate(model_inputs.input_ids, max_new_tokens=256, do_sample=False)\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "init_generated_ids = ref_policy.generate(model_inputs.input_ids, max_new_tokens=256, do_sample=False)\n",
        "init_response = tokenizer.batch_decode(init_generated_ids, skip_special_tokens=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c0e3a60-02b6-4e2c-828c-7837472f60c4",
      "metadata": {
        "id": "2c0e3a60-02b6-4e2c-828c-7837472f60c4"
      },
      "outputs": [],
      "source": [
        "print(\"======== BEFORE TUNING ========\")\n",
        "print(init_response)\n",
        "print()\n",
        "\n",
        "print(\"======== AFTER TUNING ========\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5424c50",
      "metadata": {
        "id": "e5424c50"
      },
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –Ω–∞ —Ö–∞–±\n",
        "\n",
        "model.push_to_hub(f\"{REPO_NAME}-ppo\")\n",
        "tokenizer.push_to_hub(f\"{REPO_NAME}-ppo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b4c547e-f9e7-42c4-acb4-513853326e76",
      "metadata": {
        "id": "6b4c547e-f9e7-42c4-acb4-513853326e76"
      },
      "source": [
        "## –ê–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–∏ [2 –±–∞–ª–ª]\n",
        "\n",
        "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –º–æ–¥–µ–ª—å (–æ—Ç DPO –∏ PPO).\n",
        "–ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫–∏ –ª–æ–≥–ø—Ä–æ–± –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –∏ —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª—å –Ω–µ –≤–∏–¥–µ–ª–∞.\n",
        "–ü–æ–¥–æ–π–¥–µ—Ç –ª—é–±–æ–π –Ω–µ —Å–∏–ª—å–Ω–æ –±–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç —Å hugging face.\n",
        "\n",
        "–°—á–∏—Ç–∞–µ—Ç –ª–∏ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d521c8ba-b7f1-4d93-9410-53a753d6211a",
      "metadata": {
        "id": "d521c8ba-b7f1-4d93-9410-53a753d6211a"
      },
      "source": [
        "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å (–æ—Ç DPO –∏–ª–∏ PPO). –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≥—Ä–∞—Ñ–∏–∫–∏ –ª–æ–≥–ø—Ä–æ–± –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –∏ –∫–∞–∫–∏—Ö –Ω–∏–±—É–¥—å –µ—â–µ, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª—å –Ω–µ –≤–∏–¥–µ–ª–∞. –°—á–∏—Ç–∞–µ—Ç –ª–∏ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ –±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1356ece6-c7d5-4431-8558-5be5908d8654",
      "metadata": {
        "id": "1356ece6-c7d5-4431-8558-5be5908d8654"
      },
      "outputs": [],
      "source": [
        "# ========== TODO ==========\n",
        "#      –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å      =\n",
        "# ==========================\n",
        "todo()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b84b1b",
      "metadata": {
        "id": "69b84b1b"
      },
      "source": [
        "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∞–ª–ª—ã\n",
        "\n",
        "–í—ã —Ç–∞–∫–∂–µ –º–æ–∂–Ω–æ –∑–∞—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∞–ª–ª—ã:\n",
        "- –û—Ñ–æ—Ä–º–∏—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –Ω–∞ ü§ó (–º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é, —Ç–∞–∫ –∫–∞–∫ —É –Ω–∞—Å 3 —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è): –∫–∞—Ä—Ç–æ—á–∫–∞ –º–æ–¥–µ–ª–∏ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –∑–∞–¥–∞–Ω–∏—è, —Ä–µ–ø–æ—Ä—Ç–æ–º –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ **[2 –±–∞–ª–ª–∞]**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37de87c4",
      "metadata": {
        "id": "37de87c4"
      },
      "source": [
        "# –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ä–∞–∑–¥–µ–ª –¥–ª—è –ø—Ä–æ–≤–µ—Ä—è—é—â–µ–≥–æ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a0c0c7",
      "metadata": {
        "id": "33a0c0c7"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "DPO_REPO_NAME = f\"{REPO_NAME}-dpo\"\n",
        "PPO_REPO_NAME = f\"{REPO_NAME}-ppo\"\n",
        "REWARD_MODEL_REPO_NAME = f\"{REPO_NAME}-reward-model\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(DPO_REPO_NAME)\n",
        "check_model = AutoModelForCausalLM.from_pretrained(DPO_REPO_NAME)\n",
        "check_model = check_model.to(device)\n",
        "check_model = check_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7605867",
      "metadata": {
        "id": "c7605867"
      },
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What's your morning routine like?\"}]\n",
        "\n",
        "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "generated_ids = check_model.generate(model_inputs.input_ids, max_new_tokens=256, do_sample=False)\n",
        "response = tokenizer.decode(generated_ids, skip_special_tokens=True)[0]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
